
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Multi-part curriculum teaching Generative AI from concepts to code">
      
      
        <meta name="author" content="AI Advocacy">
      
      
        <link rel="canonical" href="https://nitya.github.io/generative-ai-for-beginners/02-exploring-and-comparing-different-llms/">
      
      
        <link rel="prev" href="../01-introduction-to-genai/">
      
      
        <link rel="next" href="../03-using-generative-ai-responsibly/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.45">
    
    
      
        <title>2. Compare LLMs - Generative AI For Beginners</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.0253249f.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#exploring-and-comparing-different-llms" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Generative AI For Beginners" class="md-header__button md-logo" aria-label="Generative AI For Beginners" data-md-component="logo">
      
  <img src="../img/logo.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Generative AI For Beginners
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              2. Compare LLMs
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="blue" data-md-color-accent="pink"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 2c-1.82 0-3.53.5-5 1.35C8 5.08 10 8.3 10 12s-2 6.92-5 8.65C6.47 21.5 8.18 22 10 22a10 10 0 0 0 10-10A10 10 0 0 0 10 2"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="amber" data-md-color-accent="cyan"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/microsoft/generative-ai-for-beginners" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    microsoft/generative-ai-for-beginners
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
    
  
  Welcome

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../00-course-setup/" class="md-tabs__link">
          
  
  Getting Started

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../01-introduction-to-genai/" class="md-tabs__link">
          
  
  Lessons

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Generative AI For Beginners" class="md-nav__button md-logo" aria-label="Generative AI For Beginners" data-md-component="logo">
      
  <img src="../img/logo.svg" alt="logo">

    </a>
    Generative AI For Beginners
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/microsoft/generative-ai-for-beginners" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    microsoft/generative-ai-for-beginners
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Welcome
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Getting Started
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Getting Started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../00-course-setup/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../00-course-setup/SETUP/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Setup
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Lessons
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Lessons
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01-introduction-to-genai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1. Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    2. Compare LLMs
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    2. Compare LLMs
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-goals" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Goals
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#understand-different-types-of-llms" class="md-nav__link">
    <span class="md-ellipsis">
      Understand different types of LLMs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Understand different types of LLMs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#foundation-models-versus-llms" class="md-nav__link">
    <span class="md-ellipsis">
      Foundation Models versus LLMs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#open-source-versus-proprietary-models" class="md-nav__link">
    <span class="md-ellipsis">
      Open Source versus Proprietary Models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#embedding-versus-image-generation-versus-text-and-code-generation" class="md-nav__link">
    <span class="md-ellipsis">
      Embedding versus Image generation versus Text and Code generation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#encoder-decoder-versus-decoder-only" class="md-nav__link">
    <span class="md-ellipsis">
      Encoder-Decoder versus Decoder-only
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#service-versus-model" class="md-nav__link">
    <span class="md-ellipsis">
      Service versus Model
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-to-test-and-iterate-with-different-models-to-understand-performance-on-azure" class="md-nav__link">
    <span class="md-ellipsis">
      How to test and iterate with different models to understand performance on Azure
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#improving-llm-results" class="md-nav__link">
    <span class="md-ellipsis">
      Improving LLM results
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Improving LLM results">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#prompt-engineering-with-context" class="md-nav__link">
    <span class="md-ellipsis">
      Prompt Engineering with Context
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#retrieval-augmented-generation-rag" class="md-nav__link">
    <span class="md-ellipsis">
      Retrieval Augmented Generation (RAG)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fine-tuned-model" class="md-nav__link">
    <span class="md-ellipsis">
      Fine-tuned model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trained-model" class="md-nav__link">
    <span class="md-ellipsis">
      Trained model
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#knowledge-check" class="md-nav__link">
    <span class="md-ellipsis">
      Knowledge check
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#challenge" class="md-nav__link">
    <span class="md-ellipsis">
      🚀 Challenge
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#great-work-continue-your-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Great Work, Continue Your Learning
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03-using-generative-ai-responsibly/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3. Responsible AI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../04-prompt-engineering-fundamentals/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4. Prompt Engineering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../05-advanced-prompts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5. Advanced Prompts
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../06-text-generation-apps/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6. Text Generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../07-building-chat-applications/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    7. Chat Applications
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../08-building-search-applications/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    8. Search Applications
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../09-building-image-applications/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    9. Image Applications
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../10-building-low-code-ai-applications/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    10. Low Code Applications
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Integrating with11-integrating-with-function-calling/README.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    11. Function Calling
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../12-designing-ux-for-ai-applications/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    12. Designing UX for AI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../13-securing-ai-applications/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    13. Securing AI Applications
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../14-the-generative-ai-application-lifecycle/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    14. Generative AI App Lifecycle
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../15-rag-and-vector-databases/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    15. RAG and Vector Databases
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../16-open-source-models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    16. Open Source Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../17-ai-agents/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    17. AI Agents
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../18-fine-tuning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    18. Fine Tuning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../19-slm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    19. Small Language Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../20-mistral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    20. Mistral
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../21-meta/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    21. Meta
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#learning-goals" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Goals
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#understand-different-types-of-llms" class="md-nav__link">
    <span class="md-ellipsis">
      Understand different types of LLMs
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Understand different types of LLMs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#foundation-models-versus-llms" class="md-nav__link">
    <span class="md-ellipsis">
      Foundation Models versus LLMs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#open-source-versus-proprietary-models" class="md-nav__link">
    <span class="md-ellipsis">
      Open Source versus Proprietary Models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#embedding-versus-image-generation-versus-text-and-code-generation" class="md-nav__link">
    <span class="md-ellipsis">
      Embedding versus Image generation versus Text and Code generation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#encoder-decoder-versus-decoder-only" class="md-nav__link">
    <span class="md-ellipsis">
      Encoder-Decoder versus Decoder-only
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#service-versus-model" class="md-nav__link">
    <span class="md-ellipsis">
      Service versus Model
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-to-test-and-iterate-with-different-models-to-understand-performance-on-azure" class="md-nav__link">
    <span class="md-ellipsis">
      How to test and iterate with different models to understand performance on Azure
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#improving-llm-results" class="md-nav__link">
    <span class="md-ellipsis">
      Improving LLM results
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Improving LLM results">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#prompt-engineering-with-context" class="md-nav__link">
    <span class="md-ellipsis">
      Prompt Engineering with Context
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#retrieval-augmented-generation-rag" class="md-nav__link">
    <span class="md-ellipsis">
      Retrieval Augmented Generation (RAG)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fine-tuned-model" class="md-nav__link">
    <span class="md-ellipsis">
      Fine-tuned model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#trained-model" class="md-nav__link">
    <span class="md-ellipsis">
      Trained model
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#knowledge-check" class="md-nav__link">
    <span class="md-ellipsis">
      Knowledge check
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#challenge" class="md-nav__link">
    <span class="md-ellipsis">
      🚀 Challenge
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#great-work-continue-your-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Great Work, Continue Your Learning
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="exploring-and-comparing-different-llms">Exploring and comparing different LLMs<a class="headerlink" href="#exploring-and-comparing-different-llms" title="Permanent link">&para;</a></h1>
<p><a href="https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst"><img alt="Exploring and comparing different LLMs" src="images/02-lesson-banner.png?WT.mc_id=academic-105485-koreyst" /></a></p>
<blockquote>
<p><em>Click the image above to view video of this lesson</em></p>
</blockquote>
<p>With the previous lesson, we have seen how Generative AI is changing the technology landscape, how Large Language Models (LLMs) work and how a business - like our startup - can apply them to their use cases and grow! In this chapter, we're looking to compare and contrast different types of large language models (LLMs) to understand their pros and cons.</p>
<p>The next step in our startup's journey is exploring the current landscape of LLMs and understanding which are suitable for our use case.</p>
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">&para;</a></h2>
<p>This lesson will cover:</p>
<ul>
<li>Different types of LLMs in the current landscape.</li>
<li>Testing, iterating, and comparing different models for your use case in Azure.</li>
<li>How to deploy an LLM.</li>
</ul>
<h2 id="learning-goals">Learning Goals<a class="headerlink" href="#learning-goals" title="Permanent link">&para;</a></h2>
<p>After completing this lesson, you will be able to:</p>
<ul>
<li>Select the right model for your use case.</li>
<li>Understand how to test, iterate, and improve performance of your model.</li>
<li>Know how businesses deploy models.</li>
</ul>
<h2 id="understand-different-types-of-llms">Understand different types of LLMs<a class="headerlink" href="#understand-different-types-of-llms" title="Permanent link">&para;</a></h2>
<p>LLMs can have multiple categorizations based on their architecture, training data, and use case. Understanding these differences will help our startup select the right model for the scenario, and understand how to test, iterate, and improve performance.</p>
<p>There are many different types of LLM models, your choice of model depends on what you aim to use them for, your data, how much you're ready to pay and more.</p>
<p>Depending on if you aim to use the models for text, audio, video, image generation and so on, you might opt for a different type of model.</p>
<ul>
<li>
<p><strong>Audio and speech recognition</strong>. For this purpose, Whisper-type models are a great choice as they're general-purpose and aimed at speech recognition. It's trained on diverse audio and can perform multilingual speech recognition. Learn more about <a href="https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst">Whisper type models here</a>.</p>
</li>
<li>
<p><strong>Image generation</strong>. For image generation, DALL-E and Midjourney are two very known choices. DALL-E is offered by Azure OpenAI. <a href="https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst">Read more about DALL-E here</a> and also in Chapter 9 of this curriculum.</p>
</li>
<li>
<p><strong>Text generation</strong>. Most models are trained on text generation and you have a large variety of choices from GPT-3.5 to GPT-4. They come at different costs with GPT-4 being the most expensive. It's worth looking into the <a href="https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst">Azure OpenAI playground</a> to evaluate which models best fit your needs in terms of capability and cost.</p>
</li>
<li>
<p><strong>Multi-modality</strong>. If you're looking to handle multiple types of data in input and output, you might want to look into models like <a href="https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst">gpt-4 turbo with vision or gpt-4o</a> - the latest releases of OpenAI models - which are capable to combine natural language processing to visual understanding, enabling interactions through multi-modal interfaces.</p>
</li>
</ul>
<p>Selecting a model means you get some basic capabilities, that might not be enough however. Often you have company specific data that you somehow need to tell the LLM about. There are a few different choices on how to approach that, more on that in the upcoming sections.</p>
<h3 id="foundation-models-versus-llms">Foundation Models versus LLMs<a class="headerlink" href="#foundation-models-versus-llms" title="Permanent link">&para;</a></h3>
<p>The term Foundation Model was <a href="https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst">coined by Stanford researchers</a> and defined as an AI model that follows some criteria, such as:</p>
<ul>
<li><strong>They are trained using unsupervised learning or self-supervised learning</strong>, meaning they are trained on unlabeled multi-modal data, and they do not require human annotation or labeling of data for their training process.</li>
<li><strong>They are very large models</strong>, based on very deep neural networks trained on billions of parameters.</li>
<li><strong>They are normally intended to serve as a ‘foundation’ for other models</strong>, meaning they can be used as a starting point for other models to be built on top of, which can be done by fine-tuning.</li>
</ul>
<p><img alt="Foundation Models versus LLMs" src="images/FoundationModel.png?WT.mc_id=academic-105485-koreyst" /></p>
<p>Image source: <a href="https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404">Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium
</a></p>
<p>To further clarify this distinction, let’s take ChatGPT as an example. To build the first version of ChatGPT, a model called GPT-3.5 served as the foundation model. This means that OpenAI used some chat-specific data to create a tuned version of GPT-3.5 that was specialized in performing well in conversational scenarios, such as chatbots.</p>
<p><img alt="Foundation Model" src="images/Multimodal.png?WT.mc_id=academic-105485-koreyst" /></p>
<p>Image source: <a href="https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst">2108.07258.pdf (arxiv.org)</a></p>
<h3 id="open-source-versus-proprietary-models">Open Source versus Proprietary Models<a class="headerlink" href="#open-source-versus-proprietary-models" title="Permanent link">&para;</a></h3>
<p>Another way to categorize LLMs is whether they are open source or proprietary.</p>
<p>Open-source models are models that are made available to the public and can be used by anyone. They are often made available by the company that created them, or by the research community. These models are allowed to be inspected, modified, and customized for the various use cases in LLMs. However, they are not always optimized for production use, and may not be as performant as proprietary models. Plus, funding for open-source models can be limited, and they may not be maintained long term or may not be updated with the latest research. Examples of popular open source models include <a href="https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst">Alpaca</a>, <a href="https://huggingface.co/bigscience/bloom">Bloom</a> and <a href="https://llama.meta.com">LLaMA</a>.</p>
<p>Proprietary models are models that are owned by a company and are not made available to the public. These models are often optimized for production use. However, they are not allowed to be inspected, modified, or customized for different use cases. Plus, they are not always available for free, and may require a subscription or payment to use. Also, users do not have control over the data that is used to train the model, which means they should entrust the model owner with ensuring commitment to data privacy and responsible use of AI. Examples of popular proprietary models include <a href="https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst">OpenAI models</a>, <a href="https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst">Google Bard</a> or <a href="https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst">Claude 2</a>.</p>
<h3 id="embedding-versus-image-generation-versus-text-and-code-generation">Embedding versus Image generation versus Text and Code generation<a class="headerlink" href="#embedding-versus-image-generation-versus-text-and-code-generation" title="Permanent link">&para;</a></h3>
<p>LLMs can also be categorized by the output they generate.</p>
<p>Embeddings are a set of models that can convert text into a numerical form, called embedding, which is a numerical representation of the input text. Embeddings make it easier for machines to understand the relationships between words or sentences and can be consumed as inputs by other models, such as classification models, or clustering models that have better performance on numerical data. Embedding models are often used for transfer learning, where a model is built for a surrogate task for which there’s an abundance of data, and then the model weights (embeddings) are re-used for other downstream tasks. An example of this category is <a href="https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst">OpenAI embeddings</a>.</p>
<p><img alt="Embedding" src="images/Embedding.png?WT.mc_id=academic-105485-koreyst" /></p>
<p>Image generation models are models that generate images. These models are often used for image editing, image synthesis, and image translation. Image generation models are often trained on large datasets of images, such as <a href="https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst">LAION-5B</a>, and can be used to generate new images or to edit existing images with inpainting, super-resolution, and colorization techniques. Examples include <a href="https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst">DALL-E-3</a> and <a href="https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst">Stable Diffusion models</a>.</p>
<p><img alt="Image generation" src="images/Image.png?WT.mc_id=academic-105485-koreyst" /></p>
<p>Text and code generation models are models that generate text or code. These models are often used for text summarization, translation, and question answering. Text generation models are often trained on large datasets of text, such as <a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst">BookCorpus</a>, and can be used to generate new text, or to answer questions. Code generation models, like <a href="https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst">CodeParrot</a>, are often trained on large datasets of code, such as GitHub, and can be used to generate new code, or to fix bugs in existing code.</p>
<p><img alt="Text and code generation" src="images/Text.png?WT.mc_id=academic-105485-koreyst" /></p>
<h3 id="encoder-decoder-versus-decoder-only">Encoder-Decoder versus Decoder-only<a class="headerlink" href="#encoder-decoder-versus-decoder-only" title="Permanent link">&para;</a></h3>
<p>To talk about the different types of architectures of LLMs, let's use an analogy.</p>
<p>Imagine your manager gave you a task for writing a quiz for the students. You have two colleagues; one oversees creating the content and the other oversees reviewing them.</p>
<p>The content creator is like a Decoder only model, they can look at the topic and see what you already wrote and then he can write a course based on that. They are very good at writing engaging and informative content, but they are not very good at understanding the topic and the learning objectives. Some examples of Decoder models are GPT family models, such as GPT-3.</p>
<p>The reviewer is like an Encoder only model, they look at the course written and the answers, noticing the relationship between them and understanding context, but they are not good at generating content. An example of Encoder only model would be BERT.</p>
<p>Imagine that we can have someone as well who could create and review the quiz, this is an Encoder-Decoder model. Some examples would be BART and T5.</p>
<h3 id="service-versus-model">Service versus Model<a class="headerlink" href="#service-versus-model" title="Permanent link">&para;</a></h3>
<p>Now, let's talk about the difference between a service and a model. A service is a product that is offered by a Cloud Service Provider, and is often a combination of models, data, and other components. A model is the core component of a service, and is often a foundation model, such as an LLM.</p>
<p>Services are often optimized for production use and are often easier to use than models, via a graphical user interface. However, services are not always available for free, and may require a subscription or payment to use, in exchange for leveraging the service owner’s equipment and resources, optimizing expenses and scaling easily. An example of service is <a href="https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst">Azure OpenAI Service</a>, which offers a pay-as-you-go rate plan, meaning users are charged proportionally to how much they use the service Also, Azure OpenAI Service offers enterprise-grade security and responsible AI framework on top of the models' capabilities.</p>
<p>Models are just the Neural Network, with the parameters, weights, and others. Allowing companies to run locally, however, would need to buy equipment, build structure to scale and buy a license or use an open-source model. A model like LLaMA is available to be used, requiring computational power to run the model.</p>
<h2 id="how-to-test-and-iterate-with-different-models-to-understand-performance-on-azure">How to test and iterate with different models to understand performance on Azure<a class="headerlink" href="#how-to-test-and-iterate-with-different-models-to-understand-performance-on-azure" title="Permanent link">&para;</a></h2>
<p>Once our team has explored the current LLMs landscape and identified some good candidates for their scenarios, the next step is testing them on their data and on their workload. This is an iterative process, done by experiments and measures.
Most of the models we mentioned in previous paragraphs (OpenAI models, open source models like Llama2, and Hugging Face transformers) are available in the <a href="https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst">Model Catalog</a> in <a href="https://ai.azure.com/?WT.mc_id=academic-105485-koreyst">Azure AI Studio</a>.</p>
<p><a href="https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst">Azure AI Studio</a> is a Cloud Platform designed for developers to build generative AI applications and manage the whole development lifecycle - from experimentation to evaluation - by combining all Azure AI services into a single hub with an handy GUI. The Model Catalog in Azure AI Studio enables the user to:</p>
<ul>
<li>Find the Foundation Model of interest in the catalog - either proprietary or open source, filtering by task, license, or name. To improve searchability, the models are organized into collections, like Azure OpenAI collection, Hugging Face collection, and more.</li>
</ul>
<p><img alt="Model catalog" src="images/AzureAIStudioModelCatalog.png?WT.mc_id=academic-105485-koreyst" /></p>
<ul>
<li>Review the model card, including a detailed description of intended use and training data, code samples and evaluation results on internal evaluations library.</li>
</ul>
<p><img alt="Model card" src="images/ModelCard.png?WT.mc_id=academic-105485-koreyst" /></p>
<ul>
<li>Compare benchmarks across models and datasets available in the industry to assess which one meets the business scenario, through the <a href="https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst">Model Benchmarks</a> pane.</li>
</ul>
<p><img alt="Model benchmarks" src="images/ModelBenchmarks.png?WT.mc_id=academic-105485-koreyst" /></p>
<ul>
<li>Fine-tune the model on custom training data to improve model performance in a specific workload, leveraging the experimentation and tracking capabilities of Azure AI Studio.</li>
</ul>
<p><img alt="Model fine-tuning" src="images/FineTuning.png?WT.mc_id=academic-105485-koreyst" /></p>
<ul>
<li>Deploy the original pre-trained model or the fine-tuned version to a remote real time inference - managed compute - or serverless api endpoint - <a href="https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst">pay-as-you-go</a> - to enable applications to consume it.</li>
</ul>
<p><img alt="Model deployment" src="images/ModelDeploy.png?WT.mc_id=academic-105485-koreyst" /></p>
<blockquote>
<p>[!NOTE]
Not all models in the catalog are currently available for fine-tuning and/or pay-as-you-go deployment. Check the model card for details on the model's capabilities and limitations.</p>
</blockquote>
<h2 id="improving-llm-results">Improving LLM results<a class="headerlink" href="#improving-llm-results" title="Permanent link">&para;</a></h2>
<p>We’ve explored with our startup team different kinds of LLMs and a Cloud Platform (Azure Machine Learning) enabling us to compare different models, evaluate them on test data, improve performance and deploy them on inference endpoints.</p>
<p>But when shall they consider fine-tuning a model rather than using a pre-trained one? Are there other approaches to improve model performance on specific workloads?</p>
<p>There are several approaches a business can use to get the results they need from an LLM. You can select different types of models with different degrees of training when deploying an LLM in production, with different levels of complexity, cost, and quality. Here are some different approaches:</p>
<ul>
<li>
<p><strong>Prompt engineering with context</strong>. The idea is to provide enough context when you prompt to ensure you get the responses you need.</p>
</li>
<li>
<p><strong>Retrieval Augmented Generation, RAG</strong>. Your data might exist in a database or web endpoint for example, to ensure this data, or a subset of it, is included at the time of prompting, you can fetch the relevant data and make that part of the user's prompt.</p>
</li>
<li>
<p><strong>Fine-tuned model</strong>. Here, you trained the model further on your own data which leads to the model being more exact and responsive to your needs but might be costly.</p>
</li>
</ul>
<p><img alt="LLMs deployment" src="images/Deploy.png?WT.mc_id=academic-105485-koreyst" /></p>
<p>Img source: <a href="https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst">Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog</a></p>
<h3 id="prompt-engineering-with-context">Prompt Engineering with Context<a class="headerlink" href="#prompt-engineering-with-context" title="Permanent link">&para;</a></h3>
<p>Pre-trained LLMs work very well on generalized natural language tasks, even by calling them with a short prompt, like a sentence to complete or a question – the so-called “zero-shot” learning.</p>
<p>However, the more the user can frame their query, with a detailed request and examples – the Context – the more accurate and closest to user’s expectations the answer will be. In this case, we talk about “one-shot” learning if the prompt includes only one example and “few shot learning” if it includes multiple examples.
Prompt engineering with context is the most cost-effective approach to kick-off with.</p>
<h3 id="retrieval-augmented-generation-rag">Retrieval Augmented Generation (RAG)<a class="headerlink" href="#retrieval-augmented-generation-rag" title="Permanent link">&para;</a></h3>
<p>LLMs have the limitation that they can use only the data that has been used during their training to generate an answer. This means that they don’t know anything about the facts that happened after their training process, and they cannot access non-public information (like company data).
This can be overcome through RAG, a technique that augments prompt with external data in the form of chunks of documents, considering prompt length limits. This is supported by Vector database tools (like <a href="https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst">Azure Vector Search</a>) that retrieve the useful chunks from varied pre-defined data sources and add them to the prompt Context.</p>
<p>This technique is very helpful when a business doesn’t have enough data, enough time, or resources to fine-tune an LLM, but still wishes to improve performance on a specific workload and reduce risks of fabrications, i.e., mystification of reality or harmful content.</p>
<h3 id="fine-tuned-model">Fine-tuned model<a class="headerlink" href="#fine-tuned-model" title="Permanent link">&para;</a></h3>
<p>Fine-tuning is a process that leverages transfer learning to ‘adapt’ the model to a downstream task or to solve a specific problem. Differently from few-shot learning and RAG, it results in a new model being generated, with updated weights and biases. It requires a set of training examples consisting of a single input (the prompt) and its associated output (the completion).
This would be the preferred approach if:</p>
<ul>
<li>
<p><strong>Using fine-tuned models</strong>. A business would like to use fine-tuned less capable models (like embedding models) rather than high performance models, resulting in a more cost effective and fast solution.</p>
</li>
<li>
<p><strong>Considering latency</strong>. Latency is important for a specific use-case, so it’s not possible to use very long prompts or the number of examples that should be learned from the model doesn’t fit with the prompt length limit.</p>
</li>
<li>
<p><strong>Staying up to date</strong>. A business has a lot of high-quality data and ground truth labels and the resources required to maintain this data up to date over time.</p>
</li>
</ul>
<h3 id="trained-model">Trained model<a class="headerlink" href="#trained-model" title="Permanent link">&para;</a></h3>
<p>Training an LLM from scratch is without a doubt the most difficult and the most complex approach to adopt, requiring massive amounts of data, skilled resources, and appropriate computational power. This option should be considered only in a scenario where a business has a domain-specific use case and a large amount of domain-centric data.</p>
<h2 id="knowledge-check">Knowledge check<a class="headerlink" href="#knowledge-check" title="Permanent link">&para;</a></h2>
<p>What could be a good approach to improve LLM completion results?</p>
<ol>
<li>Prompt engineering with context</li>
<li>RAG</li>
<li>Fine-tuned model</li>
</ol>
<p>A:3, if you have the time and resources and high quality data, fine-tuning is the better option to stay up to date. However, if you're looking at improving things and you're lacking time it's worth considering RAG first.</p>
<h2 id="challenge">🚀 Challenge<a class="headerlink" href="#challenge" title="Permanent link">&para;</a></h2>
<p>Read up more on how you can <a href="https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst">use RAG</a> for your business.</p>
<h2 id="great-work-continue-your-learning">Great Work, Continue Your Learning<a class="headerlink" href="#great-work-continue-your-learning" title="Permanent link">&para;</a></h2>
<p>After completing this lesson, check out our <a href="https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst">Generative AI Learning collection</a> to continue leveling up your Generative AI knowledge!</p>
<p>Head over to Lesson 3 where we will look at how to <a href="../03-using-generative-ai-responsibly/?WT.mc_id=academic-105485-koreyst">build with Generative AI Responsibly</a>!</p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../01-introduction-to-genai/" class="md-footer__link md-footer__link--prev" aria-label="Previous: 1. Introduction">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                1. Introduction
              </div>
            </div>
          </a>
        
        
          
          <a href="../03-using-generative-ai-responsibly/" class="md-footer__link md-footer__link--next" aria-label="Next: 3. Responsible AI">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                3. Responsible AI
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 - present Microsoft

    </div>
  
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.instant", "navigation.expand", "navigation.instant.progress", "navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.path", "navigation.top", "toc.follow", "navigation.footer", "content.code.copy", "content.tabs.link"], "search": "../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>