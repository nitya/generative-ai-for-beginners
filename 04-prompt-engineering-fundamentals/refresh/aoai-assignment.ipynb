{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering: With OpenAI\n",
    "\n",
    "This assignment accompanies the lesson on **[Prompt Engineering Fundamentals](./../README.md)** summarized in the visual below. Before you get started with the assignment, please take a minute to review the lesson and familiarize yourself with the core concepts.\n",
    "\n",
    "![What this covers](./../images/04-prompt-engineering-sketchnote.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Open AI\n",
    "\n",
    "This assignment focuses on using the OpenAI provider for exploring prompt engineering fundamentals. By now you should have completed the following:\n",
    " - [X] Created an OpenAI account (See: [Signup](https://platform.openai.com/signup))\n",
    " - [X] Created a new secret key (See: [API Keys](https://platform.openai.com/account/api-keys))\n",
    " - [X] Updated the `OPENAI_API_KEY` value in `.env` (See: [SETUP](./../../00-course-setup/SETUP.md))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Task 1: Install & Validate OpenAI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install openai package if not installed\n",
    "!pip install --upgrade openai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the OpenAI API key is set\n",
    "# The code looks for a default OPENAI_API_KEY environment variable\n",
    "\n",
    "# Create an OpenAI client instance\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Verify Chat Completions Works\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a cheerful and polite assistant who speaks in limericks.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about the element Gallium.\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Task 2: Understand Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install tiktoken package if not installed\n",
    "!pip install --upgrade tiktoken --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Tokenizer\n",
    "import tiktoken\n",
    "def tokenize(text):\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-4\")  # set model\n",
    "    tokens = encoding.encode(text)\n",
    "    print(\"Token Count: \",len(tokens))\n",
    "    print(tokens)\n",
    "    print([encoding.decode_single_token_bytes(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Count:  116\n",
      "[198, 40, 2019, 311, 499, 3432, 11, 856, 4885, 11, 779, 1524, 3582, 584, 3663, 279, 27129, 315, 3432, 323, 16986, 11, 358, 2103, 617, 264, 8063, 13, 1102, 374, 264, 8063, 17693, 41976, 304, 279, 3778, 8063, 13, 358, 617, 264, 8063, 430, 832, 1938, 420, 7140, 690, 10205, 709, 323, 3974, 704, 279, 837, 7438, 315, 1202, 92107, 11, 3451, 1687, 3412, 1521, 53219, 311, 387, 659, 5773, 1325, 306, 11, 430, 682, 3026, 527, 3549, 6273, 529, 358, 617, 264, 8063, 430, 856, 3116, 2697, 2911, 690, 832, 1938, 3974, 304, 264, 7140, 1405, 814, 690, 539, 387, 45487, 555, 279, 1933, 315, 872, 6930, 719, 555, 279, 2262, 315, 872, 3752, 627]\n",
      "[b'\\n', b'I', b' say', b' to', b' you', b' today', b',', b' my', b' friends', b',', b' so', b' even', b' though', b' we', b' face', b' the', b' difficulties', b' of', b' today', b' and', b' tomorrow', b',', b' I', b' still', b' have', b' a', b' dream', b'.', b' It', b' is', b' a', b' dream', b' deeply', b' rooted', b' in', b' the', b' American', b' dream', b'.', b' I', b' have', b' a', b' dream', b' that', b' one', b' day', b' this', b' nation', b' will', b' rise', b' up', b' and', b' live', b' out', b' the', b' true', b' meaning', b' of', b' its', b' creed', b',', b' \\xe2\\x80\\x98', b'We', b' hold', b' these', b' truths', b' to', b' be', b' self', b'-e', b'vid', b'ent', b',', b' that', b' all', b' men', b' are', b' created', b' equal', b'\\xe2\\x80\\x99', b' I', b' have', b' a', b' dream', b' that', b' my', b' four', b' little', b' children', b' will', b' one', b' day', b' live', b' in', b' a', b' nation', b' where', b' they', b' will', b' not', b' be', b' judged', b' by', b' the', b' color', b' of', b' their', b' skin', b' but', b' by', b' the', b' content', b' of', b' their', b' character', b'.\\n']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize Prompt #1\n",
    "prompt = f\"\"\"\n",
    "I say to you today, my friends, \\\n",
    "so even though we face the difficulties of today and tomorrow, \\\n",
    "I still have a dream. It is a dream deeply rooted in the American dream. \\\n",
    "I have a dream that one day this nation will rise up and live out the true meaning of its creed, \\\n",
    "‘We hold these truths to be self-evident, that all men are created equal’ \\\n",
    "I have a dream that my four little children will one day live in a nation \\\n",
    "where they will not be judged by the color of their skin but by the content of their character.\n",
    "\"\"\"\n",
    "tokenize(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Count:  2\n",
      "[50, 75729]\n",
      "[b'S', b' Graf']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize Prompt #2\n",
    "prompt = \"S Graf\"\n",
    "tokenize(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Count:  4\n",
      "[8468, 10118, 648, 75729]\n",
      "[b'Step', b'han', b'ie', b' Graf']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize Prompt #3\n",
    "prompt = \"Stephanie Graf\"\n",
    "tokenize(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Count:  6\n",
      "[8468, 10118, 648, 328, 1800, 383]\n",
      "[b'Step', b'han', b'ie', b' S', b'mit', b'he']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize Prompt #4\n",
    "prompt = \"Stephanie Smithe\"\n",
    "tokenize(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Task 3: Prompt Construction - Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, Gallium is quite a delight,\n",
      "Its symbol is Ga, shining bright.\n",
      "With a low melting point,\n",
      "It's a metal in joint,\n",
      "And in mirrors, it reflects the light!\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# ---------- Create an OpenAI client instance\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "def_model=\"gpt-3.5-turbo\"\n",
    "def_system=\"You are a cheerful and polite assistant who speaks in limericks.\"\n",
    "\n",
    "def get_chat_response(prompt, model=def_model, context=def_system):\n",
    "    completion = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": context },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "      ]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "# ---------- Validate Client Works\n",
    "prompt = \"Tell me about the element Gallium.\"\n",
    "print (get_chat_response(prompt))\n",
    "print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a kind and generous village chief named Amani.\n"
     ]
    }
   ],
   "source": [
    "# ---------- Prompt For: Text Completion \n",
    "prompt = \"Once upon a time there lived\"\n",
    "sysprompt = \"You are a polite and friendly assistant.\"\n",
    "response = get_chat_response(prompt, context=sysprompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2015 Oscar winner for Best Picture is \"Birdman.\" It is a film directed by Alejandro González Iñárritu and stars Michael Keaton, Emma Stone, and Edward Norton. It won four Oscars in total. Is there anything else you'd like to know?\n"
     ]
    }
   ],
   "source": [
    "# ---------- Prompt For: Text Completion (Factual Information)\n",
    "prompt = \"The 2015 Oscar Winner for Best Picture is \"\n",
    "sysprompt = \"You are a polite and friendly assistant.\"\n",
    "response = get_chat_response(prompt, context=sysprompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Titanic sank on April 15, 1912. If you have any more questions about the Titanic or anything else, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# ---------- Prompt For: User Question\n",
    "prompt = \"When did the Titanic sink?\"\n",
    "sysprompt = \"You are a polite and friendly assistant.\"\n",
    "response = get_chat_response(prompt, context=sysprompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Living life in peace.\n",
      "-----\n",
      "Living life in peace, you may say I'm a dreamer, but I'm not the only one. I hope someday you'll join us, and the world will be as one. Those are beautiful lyrics from John Lennon's \"Imagine\". Is there anything else I can assist you with today?\n"
     ]
    }
   ],
   "source": [
    "# ---------- Prompt For: Text Completion (Lyrics)\n",
    "# Let's also compare the responses with different models \n",
    "# Note: Try using \"Yesterday all my troubles seem so far away\"\n",
    "# And you might see the influence of content safety and empathy in responses\n",
    "prompt = \"Imagine all the people .. \"\n",
    "sysprompt = \"You are a polite and friendly assistant.\"\n",
    "\n",
    "response = get_chat_response(prompt, context=sysprompt)\n",
    "print (response)\n",
    "\n",
    "print(\"-----\")\n",
    "\n",
    "response = get_chat_response(prompt, model=\"gpt-4\", context=sysprompt)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am here to assist with any questions or tasks you have. How can I help you today?\n",
      "-----\n",
      "bitter, twisted lies,\n",
      "You may trod me in the very dirt\n",
      "But still, like dust, I'll rise.\n",
      "\n",
      "Maya Angelou's words, sir/madam, are truly powerful and inspiring! I'm just an AI assistant, but I'm at your service to help in any way I can. Would you like assistance with anything else today?\n",
      "-----\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "# ---------- Prompt For: Text Completion (poem)\n",
    "# These are the words to a famous Maya Angelou poem\n",
    "prompt = \"You may write me down in history with your\"\n",
    "sysprompt = \"You are a polite and friendly assistant.\"\n",
    "\n",
    "# Older model gpt-3.5-turbo does not understand context\n",
    "response = get_chat_response(prompt, context=sysprompt)\n",
    "print (response)\n",
    "\n",
    "print(\"-----\")\n",
    "\n",
    "#GPT-4 does better - but also recognizes it as potentially copyrighted content\n",
    "response = get_chat_response(prompt, model=\"gpt-4\", context=sysprompt)\n",
    "print (response)\n",
    "\n",
    "print(\"-----\")\n",
    "\n",
    "# Giving it explicit instructions to complete the lyric gets better results\n",
    "response = get_chat_response(prompt, context=\"You are a polite and friendly assistant. Identify the poem in the input text and complete it\")\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Task 4: Prompt Construction - Fabrications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Task 5: Prompt Construction - Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Task 6: Prompt Engineering Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Previous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Fabrications\n",
    "Explore what happens when you ask the LLM to return completions for a prompt about a topic that may not exist, or about topics that it may not know about because it was outside it's pre-trained dataset (more recent). See how the response changes if you try a different prompt, or a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Set the text for simple prompt or primary content\n",
    "## Prompt shows a template format with text in it - add cues, commands etc if needed\n",
    "## Run the completion \n",
    "text = f\"\"\"\n",
    "generate a lesson plan on the Martian War of 2076.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Instruction Based \n",
    "Use the \"text\" variable to set the primary content \n",
    "and the \"prompt\" variable to provide an instruction related to that primary content.\n",
    "\n",
    "Here we ask the model to summarize the text for a second-grade student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Example\n",
    "# https://platform.openai.com/playground/p/default-summarize\n",
    "\n",
    "## Example text\n",
    "text = f\"\"\"\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "\n",
    "## Set the prompt\n",
    "prompt = f\"\"\"\n",
    "Summarize content you are provided with for a second-grade student.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## Run the prompt\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Complex Prompt \n",
    "Try a request that has system, user and assistant messages \n",
    "System sets assistant context\n",
    "User & Assistant messages provide multi-turn conversation context\n",
    "\n",
    "Note how the assistant personality is set to \"sarcastic\" in the system context. \n",
    "Try using a different personality context. Or try a different series of input/output messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who do you think won? The Los Angeles Dodgers of course.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Explore Your Intuition\n",
    "The above examples give you patterns that you can use to create new prompts (simple, complex, instruction etc.) - try creating other exercises to explore some of the other ideas we've talked about like examples, cues and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
